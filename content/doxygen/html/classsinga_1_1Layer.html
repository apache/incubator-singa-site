<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Apache Singa: singa::Layer Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Apache Singa
   </div>
   <div id="projectbrief">A General Distributed Deep Learning Library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesinga.html">singa</a></li><li class="navelem"><a class="el" href="classsinga_1_1Layer.html">Layer</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="classsinga_1_1Layer-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">singa::Layer Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>The base layer class.  
 <a href="classsinga_1_1Layer.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="layer_8h_source.html">layer.h</a>&gt;</code></p>
<div class="dynheader">
Collaboration diagram for singa::Layer:</div>
<div class="dyncontent">
<div class="center"><img src="classsinga_1_1Layer__coll__graph.png" border="0" usemap="#singa_1_1Layer_coll__map" alt="Collaboration graph"/></div>
<!-- MAP 0 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a1462d97e5a7c0954d34b56d94eebeb9b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a1462d97e5a7c0954d34b56d94eebeb9b">Setup</a> (const Shape &amp;in_shape, const string &amp;proto_str)</td></tr>
<tr class="memdesc:a1462d97e5a7c0954d34b56d94eebeb9b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set meta data fields from a string representing a proto message.  <a href="#a1462d97e5a7c0954d34b56d94eebeb9b">More...</a><br /></td></tr>
<tr class="separator:a1462d97e5a7c0954d34b56d94eebeb9b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a302d7b93109f8d00837b72f501c1e2"><td class="memItemLeft" align="right" valign="top"><a id="a3a302d7b93109f8d00837b72f501c1e2"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a3a302d7b93109f8d00837b72f501c1e2">Setup</a> (const vector&lt; Shape &gt; &amp;in_shapes, const string &amp;proto_str)</td></tr>
<tr class="memdesc:a3a302d7b93109f8d00837b72f501c1e2"><td class="mdescLeft">&#160;</td><td class="mdescRight">'in_shapes' is the shape of the input feature for one sample <br /></td></tr>
<tr class="separator:a3a302d7b93109f8d00837b72f501c1e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17b438a539df56a539a538a939072b81"><td class="memItemLeft" align="right" valign="top"><a id="a17b438a539df56a539a538a939072b81"></a>
virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a17b438a539df56a539a538a939072b81">~Layer</a> ()</td></tr>
<tr class="memdesc:a17b438a539df56a539a538a939072b81"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destruct objects created by this layer. <br /></td></tr>
<tr class="separator:a17b438a539df56a539a538a939072b81"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaebc00e461ce04a98793381a9d1e63c1"><td class="memItemLeft" align="right" valign="top">virtual const std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#aaebc00e461ce04a98793381a9d1e63c1">layer_type</a> () const</td></tr>
<tr class="memdesc:aaebc00e461ce04a98793381a9d1e63c1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Each layer sub-class would optionaly have a type name.  <a href="#aaebc00e461ce04a98793381a9d1e63c1">More...</a><br /></td></tr>
<tr class="separator:aaebc00e461ce04a98793381a9d1e63c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3866ece143b21c76702ca4ce76e79500"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a3866ece143b21c76702ca4ce76e79500">Setup</a> (const Shape &amp;in_sample, const LayerConf &amp;conf)</td></tr>
<tr class="memdesc:a3866ece143b21c76702ca4ce76e79500"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set meta data fields configured in 'conf' (a proto message).  <a href="#a3866ece143b21c76702ca4ce76e79500">More...</a><br /></td></tr>
<tr class="separator:a3866ece143b21c76702ca4ce76e79500"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a580bee8561fae6918d4438841fb1b938"><td class="memItemLeft" align="right" valign="top"><a id="a580bee8561fae6918d4438841fb1b938"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a580bee8561fae6918d4438841fb1b938">Setup</a> (const vector&lt; Shape &gt; &amp;in_samples, const LayerConf &amp;conf)</td></tr>
<tr class="memdesc:a580bee8561fae6918d4438841fb1b938"><td class="mdescLeft">&#160;</td><td class="mdescRight">Used for layers that have multiple input tensors, e.g., concatenate layer. <br /></td></tr>
<tr class="separator:a580bee8561fae6918d4438841fb1b938"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad98c0285b0b3ffe2dfc4d5fdbc2baf16"><td class="memItemLeft" align="right" valign="top"><a id="ad98c0285b0b3ffe2dfc4d5fdbc2baf16"></a>
virtual const Shape&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#ad98c0285b0b3ffe2dfc4d5fdbc2baf16">GetOutputSampleShape</a> () const</td></tr>
<tr class="memdesc:ad98c0285b0b3ffe2dfc4d5fdbc2baf16"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return the shape of the generated <a class="el" href="classsinga_1_1Tensor.html" title="A Tensor instance is a multi-dimensional array resident on a Device (default device is the host CPU)...">Tensor</a> without the batchsize dimension. <br /></td></tr>
<tr class="separator:ad98c0285b0b3ffe2dfc4d5fdbc2baf16"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1768c424d60860b7b0208b124d68f0e9"><td class="memItemLeft" align="right" valign="top">virtual const Shape&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a1768c424d60860b7b0208b124d68f0e9">GetOutputSampleShape</a> (int k)</td></tr>
<tr class="memdesc:a1768c424d60860b7b0208b124d68f0e9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return the shape of the k-th generated tensor without the batchsize dimension.  <a href="#a1768c424d60860b7b0208b124d68f0e9">More...</a><br /></td></tr>
<tr class="separator:a1768c424d60860b7b0208b124d68f0e9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f96ab5f12aae149cdb4e94ebaefb756"><td class="memItemLeft" align="right" valign="top">virtual const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a9f96ab5f12aae149cdb4e94ebaefb756">Forward</a> (int flag, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;input)</td></tr>
<tr class="memdesc:a9f96ab5f12aae149cdb4e94ebaefb756"><td class="mdescLeft">&#160;</td><td class="mdescRight">Do feature transformation for the given 'input' tensor (denoted as x).  <a href="#a9f96ab5f12aae149cdb4e94ebaefb756">More...</a><br /></td></tr>
<tr class="separator:a9f96ab5f12aae149cdb4e94ebaefb756"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bf2b8e388ddbba2438f84c41ccc131a"><td class="memItemLeft" align="right" valign="top">virtual const vector&lt; <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a5bf2b8e388ddbba2438f84c41ccc131a">Forward</a> (int flag, const vector&lt; <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &gt; &amp;inputs)</td></tr>
<tr class="memdesc:a5bf2b8e388ddbba2438f84c41ccc131a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Do feature transformation for the given 'input' tensor (denoted as x).  <a href="#a5bf2b8e388ddbba2438f84c41ccc131a">More...</a><br /></td></tr>
<tr class="separator:a5bf2b8e388ddbba2438f84c41ccc131a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed4aa3ffd81015c702252813e0872c1e"><td class="memItemLeft" align="right" valign="top">virtual const std::pair&lt; <a class="el" href="classsinga_1_1Tensor.html">Tensor</a>, vector&lt; <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#aed4aa3ffd81015c702252813e0872c1e">Backward</a> (int flag, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;grad)</td></tr>
<tr class="memdesc:aed4aa3ffd81015c702252813e0872c1e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute gradients of this layer.  <a href="#aed4aa3ffd81015c702252813e0872c1e">More...</a><br /></td></tr>
<tr class="separator:aed4aa3ffd81015c702252813e0872c1e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30572f8078e2f958cbf93e37eb975da6"><td class="memItemLeft" align="right" valign="top">virtual const std::pair&lt; vector&lt; <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &gt;, vector&lt; <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a30572f8078e2f958cbf93e37eb975da6">Backward</a> (int flag, const vector&lt; <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &gt; &amp;grads)</td></tr>
<tr class="separator:a30572f8078e2f958cbf93e37eb975da6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ffe3b58b69ccb87c48e4172f818cba5"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a3ffe3b58b69ccb87c48e4172f818cba5">ToDevice</a> (std::shared_ptr&lt; <a class="el" href="classsinga_1_1Device.html">Device</a> &gt; device)</td></tr>
<tr class="memdesc:a3ffe3b58b69ccb87c48e4172f818cba5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Clone the layer to the given device.  <a href="#a3ffe3b58b69ccb87c48e4172f818cba5">More...</a><br /></td></tr>
<tr class="separator:a3ffe3b58b69ccb87c48e4172f818cba5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2cccba7a2b3a1bed714f9be2b8b4d520"><td class="memItemLeft" align="right" valign="top"><a id="a2cccba7a2b3a1bed714f9be2b8b4d520"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a2cccba7a2b3a1bed714f9be2b8b4d520">AsType</a> (DataType dtype)</td></tr>
<tr class="memdesc:a2cccba7a2b3a1bed714f9be2b8b4d520"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the data type of <a class="el" href="classsinga_1_1Tensor.html" title="A Tensor instance is a multi-dimensional array resident on a Device (default device is the host CPU)...">Tensor</a> in this layer. <br /></td></tr>
<tr class="separator:a2cccba7a2b3a1bed714f9be2b8b4d520"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f1ab53e65ec8592794494995164f12c"><td class="memItemLeft" align="right" valign="top"><a id="a2f1ab53e65ec8592794494995164f12c"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a2f1ab53e65ec8592794494995164f12c">ToProto</a> (LayerConf *conf) const</td></tr>
<tr class="memdesc:a2f1ab53e65ec8592794494995164f12c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Serialize the layer info (including params) into a LayerConf proto message. <br /></td></tr>
<tr class="separator:a2f1ab53e65ec8592794494995164f12c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa7386bdb843345ba6c2095c83ffbd244"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#aa7386bdb843345ba6c2095c83ffbd244">ToProtoStr</a> () const</td></tr>
<tr class="memdesc:aa7386bdb843345ba6c2095c83ffbd244"><td class="mdescLeft">&#160;</td><td class="mdescRight">Serialize the layer info, including params_, into a string representing a LayerParameter message.  <a href="#aa7386bdb843345ba6c2095c83ffbd244">More...</a><br /></td></tr>
<tr class="separator:aa7386bdb843345ba6c2095c83ffbd244"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf39129d5cc63a8f9c6e8ad069a7fc83"><td class="memItemLeft" align="right" valign="top">const vector&lt; ParamSpec &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#aaf39129d5cc63a8f9c6e8ad069a7fc83">param_specs</a> ()</td></tr>
<tr class="memdesc:aaf39129d5cc63a8f9c6e8ad069a7fc83"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return specs/configuration of all parameter instances of this layer.  <a href="#aaf39129d5cc63a8f9c6e8ad069a7fc83">More...</a><br /></td></tr>
<tr class="separator:aaf39129d5cc63a8f9c6e8ad069a7fc83"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61c0d34827ca76e7a950b48903e591be"><td class="memItemLeft" align="right" valign="top"><a id="a61c0d34827ca76e7a950b48903e591be"></a>
const ParamSpec &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a61c0d34827ca76e7a950b48903e591be">param_specs</a> (size_t i)</td></tr>
<tr class="memdesc:a61c0d34827ca76e7a950b48903e591be"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return the i-th ParamSpec. <br /></td></tr>
<tr class="separator:a61c0d34827ca76e7a950b48903e591be"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a93d307e8c2852b2c94102c8a7d198d13"><td class="memItemLeft" align="right" valign="top"><a id="a93d307e8c2852b2c94102c8a7d198d13"></a>
virtual const vector&lt; <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a93d307e8c2852b2c94102c8a7d198d13">param_values</a> ()</td></tr>
<tr class="memdesc:a93d307e8c2852b2c94102c8a7d198d13"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return pointers to parameter <a class="el" href="classsinga_1_1Tensor.html" title="A Tensor instance is a multi-dimensional array resident on a Device (default device is the host CPU)...">Tensor</a> s. <br /></td></tr>
<tr class="separator:a93d307e8c2852b2c94102c8a7d198d13"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada81666769392e45ceb216263a8786db"><td class="memItemLeft" align="right" valign="top"><a id="ada81666769392e45ceb216263a8786db"></a>
const vector&lt; string &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#ada81666769392e45ceb216263a8786db">param_names</a> ()</td></tr>
<tr class="memdesc:ada81666769392e45ceb216263a8786db"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return names of all parmaeters. <br /></td></tr>
<tr class="separator:ada81666769392e45ceb216263a8786db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32216d201842a380d739df6a78759bb9"><td class="memItemLeft" align="right" valign="top"><a id="a32216d201842a380d739df6a78759bb9"></a>
const string &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a32216d201842a380d739df6a78759bb9">param_name</a> (size_t i)</td></tr>
<tr class="memdesc:a32216d201842a380d739df6a78759bb9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return the 'i'-th parameter name. <br /></td></tr>
<tr class="separator:a32216d201842a380d739df6a78759bb9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a127ffc9ed2504e1553d45336cb589ea1"><td class="memItemLeft" align="right" valign="top">const std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1Layer.html#a127ffc9ed2504e1553d45336cb589ea1">name</a> () const</td></tr>
<tr class="memdesc:a127ffc9ed2504e1553d45336cb589ea1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Each layer instance would optionally have a name.  <a href="#a127ffc9ed2504e1553d45336cb589ea1">More...</a><br /></td></tr>
<tr class="separator:a127ffc9ed2504e1553d45336cb589ea1"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a8a7f91715c0a515eed74db963d25571f"><td class="memItemLeft" align="right" valign="top"><a id="a8a7f91715c0a515eed74db963d25571f"></a>
std::string&#160;</td><td class="memItemRight" valign="bottom"><b>name_</b></td></tr>
<tr class="separator:a8a7f91715c0a515eed74db963d25571f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a051f0211e578d2f03f76eb763b50c9cd"><td class="memItemLeft" align="right" valign="top"><a id="a051f0211e578d2f03f76eb763b50c9cd"></a>
vector&lt; ParamSpec &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>param_specs_</b></td></tr>
<tr class="separator:a051f0211e578d2f03f76eb763b50c9cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>The base layer class. </p>
<p>Generally, a layer conducts feature transformation against a set of <a class="el" href="classsinga_1_1Tensor.html" title="A Tensor instance is a multi-dimensional array resident on a Device (default device is the host CPU)...">Tensor</a> to generate a set of <a class="el" href="classsinga_1_1Tensor.html" title="A Tensor instance is a multi-dimensional array resident on a Device (default device is the host CPU)...">Tensor</a>. Each layer may have some parameters. </p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="aed4aa3ffd81015c702252813e0872c1e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aed4aa3ffd81015c702252813e0872c1e">&#9670;&nbsp;</a></span>Backward() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual const std::pair&lt;<a class="el" href="classsinga_1_1Tensor.html">Tensor</a>, vector&lt;<a class="el" href="classsinga_1_1Tensor.html">Tensor</a>&gt; &gt; singa::Layer::Backward </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>flag</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Compute gradients of this layer. </p>
<p>Specifically, there are two types of gradients:</p><ol type="1">
<li>gradient of the preceding layer, i.e., dx.</li>
<li>gradients of parameters of this layer, e.g., dw for weight matrix. 1 is an empty tensor if there is no preceding layer or there is no need to compute dx (e.g., x is from a data layer); 2 is an empty vector if this 'flag' is either kTrain or kEval for feed-forward nets, and would be used for other phases when training other nets. 'grad' is a <a class="el" href="classsinga_1_1Tensor.html" title="A Tensor instance is a multi-dimensional array resident on a Device (default device is the host CPU)...">Tensor</a> for gradient (dy) from the upper layer. </li>
</ol>

</div>
</div>
<a id="a30572f8078e2f958cbf93e37eb975da6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a30572f8078e2f958cbf93e37eb975da6">&#9670;&nbsp;</a></span>Backward() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual const std::pair&lt;vector&lt;<a class="el" href="classsinga_1_1Tensor.html">Tensor</a>&gt;, vector&lt;<a class="el" href="classsinga_1_1Tensor.html">Tensor</a>&gt; &gt; singa::Layer::Backward </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>flag</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>grads</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p></p>
<p>For <a class="el" href="classsinga_1_1Layer.html#a5bf2b8e388ddbba2438f84c41ccc131a" title="Do feature transformation for the given &#39;input&#39; tensor (denoted as x). ">Forward(int, const vector&lt;Tensor&gt;&amp;)</a> For <a class="el" href="classsinga_1_1Layer.html#a5bf2b8e388ddbba2438f84c41ccc131a" title="Do feature transformation for the given &#39;input&#39; tensor (denoted as x). ">Forward(int, const vector&lt;Tensor&gt;&amp;)</a> </p>

</div>
</div>
<a id="a9f96ab5f12aae149cdb4e94ebaefb756"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9f96ab5f12aae149cdb4e94ebaefb756">&#9670;&nbsp;</a></span>Forward() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> singa::Layer::Forward </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>flag</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Do feature transformation for the given 'input' tensor (denoted as x). </p>
<p>'flag' is either kTrain or kEval for feed-forward nets, and would be used for other phases of training other nets. For example, when training RBM, we may create an alias of this function as ComputeFeature where flag could be kPositive and kNegative. It will return a <a class="el" href="classsinga_1_1Tensor.html" title="A Tensor instance is a multi-dimensional array resident on a Device (default device is the host CPU)...">Tensor</a> (denoted as y). If the 'input' or 'output' is required for computing the gradients in <a class="el" href="classsinga_1_1Layer.html#aed4aa3ffd81015c702252813e0872c1e" title="Compute gradients of this layer. ">Backward()</a>, then buffer them as internal data. </p>

</div>
</div>
<a id="a5bf2b8e388ddbba2438f84c41ccc131a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5bf2b8e388ddbba2438f84c41ccc131a">&#9670;&nbsp;</a></span>Forward() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual const vector&lt;<a class="el" href="classsinga_1_1Tensor.html">Tensor</a>&gt; singa::Layer::Forward </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>flag</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>inputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Do feature transformation for the given 'input' tensor (denoted as x). </p>
<p>'flag' is either kTrain or kEval for feed-forward nets, and would be used for other phases of training other nets. For example, when training RBM, we may create an alias of this function as ComputeFeature where flag could be kPositive and kNegative. It will return a <a class="el" href="classsinga_1_1Tensor.html" title="A Tensor instance is a multi-dimensional array resident on a Device (default device is the host CPU)...">Tensor</a> (denoted as y). If the 'input' or 'output' is required for computing the gradients in <a class="el" href="classsinga_1_1Layer.html#aed4aa3ffd81015c702252813e0872c1e" title="Compute gradients of this layer. ">Backward()</a>, then buffer them as internal data. Accept multiple input tensors and generate multiple output tensors. If there is only one input tensor, it will call Forward(int, const <a class="el" href="classsinga_1_1Tensor.html" title="A Tensor instance is a multi-dimensional array resident on a Device (default device is the host CPU)...">Tensor</a>&amp;) by default. Users can override this function for layers who generate more than one outputs. </p>

</div>
</div>
<a id="a1768c424d60860b7b0208b124d68f0e9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1768c424d60860b7b0208b124d68f0e9">&#9670;&nbsp;</a></span>GetOutputSampleShape()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual const Shape singa::Layer::GetOutputSampleShape </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>k</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Return the shape of the k-th generated tensor without the batchsize dimension. </p>
<p>Used for layers that generate multiple tensors. </p>

</div>
</div>
<a id="aaebc00e461ce04a98793381a9d1e63c1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaebc00e461ce04a98793381a9d1e63c1">&#9670;&nbsp;</a></span>layer_type()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual const std::string singa::Layer::layer_type </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Each layer sub-class would optionaly have a type name. </p>
<p>Used for debugging and logging. </p>

</div>
</div>
<a id="a127ffc9ed2504e1553d45336cb589ea1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a127ffc9ed2504e1553d45336cb589ea1">&#9670;&nbsp;</a></span>name()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const std::string singa::Layer::name </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Each layer instance would optionally have a name. </p>
<p>Used for debugging and logging. </p>

</div>
</div>
<a id="aaf39129d5cc63a8f9c6e8ad069a7fc83"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaf39129d5cc63a8f9c6e8ad069a7fc83">&#9670;&nbsp;</a></span>param_specs()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const vector&lt;ParamSpec&gt; singa::Layer::param_specs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Return specs/configuration of all parameter instances of this layer. </p>
<p>ParamSpec. </p>

</div>
</div>
<a id="a1462d97e5a7c0954d34b56d94eebeb9b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1462d97e5a7c0954d34b56d94eebeb9b">&#9670;&nbsp;</a></span>Setup() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void singa::Layer::Setup </td>
          <td>(</td>
          <td class="paramtype">const Shape &amp;&#160;</td>
          <td class="paramname"><em>in_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const string &amp;&#160;</td>
          <td class="paramname"><em>proto_str</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Set meta data fields from a string representing a proto message. </p>
<p>'in_shape' is the shape of the input feature for one sample </p>

</div>
</div>
<a id="a3866ece143b21c76702ca4ce76e79500"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3866ece143b21c76702ca4ce76e79500">&#9670;&nbsp;</a></span>Setup() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void singa::Layer::Setup </td>
          <td>(</td>
          <td class="paramtype">const Shape &amp;&#160;</td>
          <td class="paramname"><em>in_sample</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const LayerConf &amp;&#160;</td>
          <td class="paramname"><em>conf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Set meta data fields configured in 'conf' (a proto message). </p>
<p>Some layers would use input tensor shapes for setting its parameter shapes (e.g, desen layer and convolution layer). 'in_shape' provides such shape info. It represents the shape of the <a class="el" href="classsinga_1_1Tensor.html" title="A Tensor instance is a multi-dimensional array resident on a Device (default device is the host CPU)...">Tensor</a> (with a single sample) from the last layer. After calling Setup, the shape info of parameters should be accssed correctly. Internal buffer/fields are set assuming batchsize is 1. </p>

</div>
</div>
<a id="a3ffe3b58b69ccb87c48e4172f818cba5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3ffe3b58b69ccb87c48e4172f818cba5">&#9670;&nbsp;</a></span>ToDevice()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void singa::Layer::ToDevice </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classsinga_1_1Device.html">Device</a> &gt;&#160;</td>
          <td class="paramname"><em>device</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Clone the layer to the given device. </p>
<p><a class="el" href="classsinga_1_1Layer.html" title="The base layer class. ">Layer</a> data (e.g., parameters) are deep copied. If 'device' is nullptr, then clone it one the current device. Move the layer (including its parameters and other internal <a class="el" href="classsinga_1_1Tensor.html" title="A Tensor instance is a multi-dimensional array resident on a Device (default device is the host CPU)...">Tensor</a>) onto the given device </p>

</div>
</div>
<a id="aa7386bdb843345ba6c2095c83ffbd244"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa7386bdb843345ba6c2095c83ffbd244">&#9670;&nbsp;</a></span>ToProtoStr()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string singa::Layer::ToProtoStr </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Serialize the layer info, including params_, into a string representing a LayerParameter message. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/home/moaz/incubator-singa/include/singa/model/<a class="el" href="layer_8h_source.html">layer.h</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Mon Apr 22 2019 12:27:05 for Apache Singa by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
