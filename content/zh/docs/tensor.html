


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>张量(Tensor) &mdash; singa 2.0.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../',
              VERSION:'2.0.0',
              LANGUAGE:'None',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="层(Layer)" href="layer.html" />
    <link rel="prev" title="设备(Device)" href="device.html" />
<link href="../_static/style.css" rel="stylesheet" type="text/css">
<!--link href="../_static/fontawesome-all.min.css" rel="stylesheet" type="text/css"-->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css"
  integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
<style>
  .fa:hover {
    opacity: 0.7;
  }

  .fab:hover {
    opacity: 0.7;
  }
</style>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> singa
          

          
            
            <img src="../_static/singa.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                latest
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">文档</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="installation.html">安装</a></li>
<li class="toctree-l2"><a class="reference internal" href="software_stack.html">软件架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="device.html">设备(Device)</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">张量(Tensor)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#python-api">PYTHON API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#class-singa-tensor-tensor-shape-none-device-none-dtype-0">class singa.tensor.Tensor(shape=None, device=None, dtype=0)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="layer.html">层(Layer)</a></li>
<li class="toctree-l2"><a class="reference internal" href="net.html">前馈网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="initializer.html">初始化器(Initializer)</a></li>
<li class="toctree-l2"><a class="reference internal" href="loss.html">损失(Loss)</a></li>
<li class="toctree-l2"><a class="reference internal" href="metric.html">度量(Metric)</a></li>
<li class="toctree-l2"><a class="reference internal" href="optimizer.html">优化器(Optimizer)</a></li>
<li class="toctree-l2"><a class="reference internal" href="data.html">数据(Data)</a></li>
<li class="toctree-l2"><a class="reference internal" href="image_tool.html">图像工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="snapshot.html">Snapshot</a></li>
<li class="toctree-l2"><a class="reference internal" href="utils.html">Utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_zoo/index.html">模型库</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../downloads.html">下载 SINGA</a></li>
</ul>
<p class="caption"><span class="caption-text">开发</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../develop/schedule.html">开发时间表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../develop/how-contribute.html">如何贡献给 SINGA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../develop/contribute-code.html">如何贡献代码</a></li>
</ul>
<p class="caption"><span class="caption-text">社区</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../community/source-repository.html">源代码库</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/mail-lists.html">项目邮件列表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/issue-tracking.html">问题追踪</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/team-list.html">SINGA团队</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">singa</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">文档</a> &raquo;</li>
        
      <li>张量(Tensor)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="tensor">
<h1>张量(Tensor)<a class="headerlink" href="#tensor" title="Permalink to this headline">¶</a></h1>
<p>每个Tensor实例都是一个分配在特定Device实例上的多维数组。 Tensor实例存储了变量并提供了用户不可见的支持多种设备的代数操作。注意，用户需要确保除了拷贝之外的tensor操作都是在相同的设备上进行的。</p>
<p>Tensor的实现</p>
<p>SINGA有三种Tensor函数的实现，分别在不同设备上。</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">tensor_math_cpp.h</span></code> 用Cpp实现了CppCPU上的各种操作</li>
<li><code class="docutils literal"><span class="pre">tensor_math_cuda.h</span></code> 用Cuda (和cuBLAS)实现了CudaGPU上的各种操作</li>
<li><code class="docutils literal"><span class="pre">tensor_math_opencl.h</span></code> 用OpenCL实现了OpenclGPU上的各种操作</li>
</ul>
<div class="section" id="python-api">
<h2>PYTHON API<a class="headerlink" href="#python-api" title="Permalink to this headline">¶</a></h2>
<p>用法示例：</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">singa</span> <span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">from</span> <span class="nn">singa</span> <span class="kn">import</span> <span class="n">device</span>

<span class="c1"># create a tensor with shape (2,3), default CppCPU device and float32</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">x</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)</span>

<span class="c1"># create a tensor from a numpy array</span>
<span class="n">npy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">npy</span><span class="p">)</span>

<span class="n">y</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># sample values from the uniform distribution</span>

<span class="n">z</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">mult</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># gemm -&gt; z of shape (2, 3)</span>

<span class="n">x</span> <span class="o">+=</span> <span class="n">z</span>  <span class="c1"># element-wise addition</span>

<span class="n">dev</span> <span class="o">=</span> <span class="n">device</span><span class="o">.</span><span class="n">get_default_device</span><span class="p">()</span>
<span class="n">x</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">dev</span><span class="p">)</span>  <span class="c1"># move the data to a gpu device</span>

<span class="n">r</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">s</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>  <span class="c1"># tensor -&gt; numpy array</span>
</pre></div>
</div>
<p>有两种类型的tensor函数:</p>
<p><strong>Tensor成员函数</strong></p>
<p>将会改变Tensor实例的状态</p>
<p><strong>Tensor模块化函数</strong></p>
<p>接受Tensor实例作为自变量以及返回Tensor实例</p>
<p>每个Tensor实例在读取数据前都必须做初始化</p>
<hr class="docutils" />
<div class="section" id="class-singa-tensor-tensor-shape-none-device-none-dtype-0">
<h3>class singa.tensor.Tensor(shape=None, device=None, dtype=0)<a class="headerlink" href="#class-singa-tensor-tensor-shape-none-device-none-dtype-0" title="Permalink to this headline">¶</a></h3>
<p>创建Py Tensor，封装了一个基于swig转换的CPP Tensor。
三个参数分别是Tensor的三个属性。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>shape (list<int>)</strong> – 一个列表的整形数据作为Tensor的形状。如果shape没有指定，将会创建一个伪Tensor。</li>
<li><strong>device</strong> – swig转化的使用设备模块化的Device实例。 如果为None，默认的CPU设备将会被使用。</li>
<li><strong>dtype</strong> – 数据类型。 目前，大多数操作仅支持kFloat32。</li>
</ul>
<hr class="docutils" />
<div class="section" id="t">
<h4>T()<a class="headerlink" href="#t" title="Permalink to this headline">¶</a></h4>
<p>浅拷贝。</p>
<p><strong>返回值：</strong> 一个新Tensor，共享底层数据所占内存，但标记为该tensor的转置版本。</p>
</div>
<hr class="docutils" />
<div class="section" id="add-column-v">
<h4>add_column(v)<a class="headerlink" href="#add-column-v" title="Permalink to this headline">¶</a></h4>
<p>对该Tensor每列加上一个tensor。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>v (Tensor)</strong> – 被作为一列加到原tensor的Tensor</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="add-row-v">
<h4>add_row(v)<a class="headerlink" href="#add-row-v" title="Permalink to this headline">¶</a></h4>
<p>对该tensor每行加一个tensor。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>v (Tensor)</strong> – 被作为行加到原tensor的Tensor</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="bernoulli-p">
<h4>bernoulli(p)<a class="headerlink" href="#bernoulli-p" title="Permalink to this headline">¶</a></h4>
<p>对每个元素，按照给定概率从0/1中取样。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>p (float)</strong> – 以概率p取样一个元素为1</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="clone">
<h4>clone()<a class="headerlink" href="#clone" title="Permalink to this headline">¶</a></h4>
<p><strong>返回值：</strong> 一个新Tensor，是待拷贝Tensor的深拷贝</p>
</div>
<hr class="docutils" />
<div class="section" id="copy">
<h4>copy()<a class="headerlink" href="#copy" title="Permalink to this headline">¶</a></h4>
<p>调用singa::Tensor的拷贝构造器进行浅拷贝。</p>
</div>
<hr class="docutils" />
<div class="section" id="copy-data-t">
<h4>copy_data(t)<a class="headerlink" href="#copy-data-t" title="Permalink to this headline">¶</a></h4>
<p>从另一个Tensor实例拷贝数据。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 源Tensor</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="copy-from-numpy-np-array-offset-0">
<h4>copy_from_numpy(np_array, offset=0)<a class="headerlink" href="#copy-from-numpy-np-array-offset-0" title="Permalink to this headline">¶</a></h4>
<p>从numpy数组中拷贝数据。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>np_array</strong> – 源numpy数组</li>
<li><strong>offset (int)</strong> – 目标偏移</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="deepcopy">
<h4>deepcopy()<a class="headerlink" href="#deepcopy" title="Permalink to this headline">¶</a></h4>
<p>同clone()</p>
<p><strong>返回值：</strong> 新Tensor</p>
</div>
<hr class="docutils" />
<div class="section" id="div-column-v">
<h4>div_column(v)<a class="headerlink" href="#div-column-v" title="Permalink to this headline">¶</a></h4>
<p>将Tensor每列除以v。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>v (Tensor)</strong> – 1维tensor，和源tensor的列长相同</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="div-row-v">
<h4>div_row(v)<a class="headerlink" href="#div-row-v" title="Permalink to this headline">¶</a></h4>
<p>将Tensor每行除以v。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>v (Tensor)</strong> – 1维tensor，和源tensor的行长相同</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="gaussian-mean-std">
<h4>gaussian(mean, std)<a class="headerlink" href="#gaussian-mean-std" title="Permalink to this headline">¶</a></h4>
<p>按照高斯分布对每个元素采样。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>mean (float)</strong> – 分布的均值</li>
<li><strong>std (float)</strong> – 分布的标准差</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="is-empty">
<h4>is_empty()<a class="headerlink" href="#is-empty" title="Permalink to this headline">¶</a></h4>
<p><strong>返回值：</strong> 根据tensor的形状，如果是空的返回True</p>
</div>
<hr class="docutils" />
<div class="section" id="is-transpose">
<h4>is_transpose()<a class="headerlink" href="#is-transpose" title="Permalink to this headline">¶</a></h4>
<p><strong>返回值：</strong> 如果内部数据被转置则返回True，否则返回False</p>
</div>
<hr class="docutils" />
<div class="section" id="l1">
<h4>l1()<a class="headerlink" href="#l1" title="Permalink to this headline">¶</a></h4>
<p><strong>返回值：</strong> L1 norm</p>
</div>
<hr class="docutils" />
<div class="section" id="l2">
<h4>l2()<a class="headerlink" href="#l2" title="Permalink to this headline">¶</a></h4>
<p><strong>返回值：</strong> L2 norm</p>
</div>
<hr class="docutils" />
<div class="section" id="memsize">
<h4>memsize()<a class="headerlink" href="#memsize" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><strong>返回值：</strong> 被分配给该tensor的Bytes数</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="mult-column-v">
<h4>mult_column(v)<a class="headerlink" href="#mult-column-v" title="Permalink to this headline">¶</a></h4>
<p>将tensor每列和v做元素级别乘法。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>v (Tensor)</strong> – 1维tensor，同源tensor列长等长</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="mult-row-v">
<h4>mult_row(v)<a class="headerlink" href="#mult-row-v" title="Permalink to this headline">¶</a></h4>
<p>将tensor每行和v做元素级别乘法。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>v (Tensor)</strong> – 1维tensor，同源tensor行长等长</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="ndim">
<h4>ndim()<a class="headerlink" href="#ndim" title="Permalink to this headline">¶</a></h4>
<p><strong>返回值：</strong> tensor的维度</p>
</div>
<hr class="docutils" />
<div class="section" id="reset-like-t">
<h4>reset_like(t)<a class="headerlink" href="#reset-like-t" title="Permalink to this headline">¶</a></h4>
<p>根据给定tensor重置源tensor形状，数据类型和设备。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 需要重置的tensor</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="set-value-x">
<h4>set_value(x)<a class="headerlink" href="#set-value-x" title="Permalink to this headline">¶</a></h4>
<p>设置所有元素值为给定值。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>x(float)</strong> - 待设定的值</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="size">
<h4>size()<a class="headerlink" href="#size" title="Permalink to this headline">¶</a></h4>
<p><strong>返回值：</strong> tensor中的元素个数</p>
</div>
<hr class="docutils" />
<div class="section" id="to-device-device">
<h4>to_device(device)<a class="headerlink" href="#to-device-device" title="Permalink to this headline">¶</a></h4>
<p>将tensor中数据传到指定设备上。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>device</strong> - 从CudaGPU/CppCPU/OpenclGPU转换的swig设备</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="to-host">
<h4>to_host()<a class="headerlink" href="#to-host" title="Permalink to this headline">¶</a></h4>
<p>将tensor数据传到默认的CppCPU设备上。</p>
</div>
<hr class="docutils" />
<div class="section" id="uniform-low-high">
<h4>uniform(low, high)<a class="headerlink" href="#uniform-low-high" title="Permalink to this headline">¶</a></h4>
<p>从均匀分布中进行采样。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>low (float)</strong> – 下界</li>
<li><strong>high (float)</strong> – 上界</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-abs-t">
<h4>singa.tensor.abs(t)<a class="headerlink" href="#singa-tensor-abs-t" title="Permalink to this headline">¶</a></h4>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t(Tensor)</strong> - 输入tensor</li>
</ul>
<p><strong>返回值：</strong> 一个新tensor，其元素值为y=abs(x)，x是t中的元素</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-add-lhs-rhs-ret-none">
<h4>singa.tensor.add(lhs, rhs, ret=None)<a class="headerlink" href="#singa-tensor-add-lhs-rhs-ret-none" title="Permalink to this headline">¶</a></h4>
<p>元素级别加法。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>lhs (Tensor)</strong> – 左操作tensor</li>
<li><strong>rhs (Tensor)</strong> – 右操作tensor</li>
<li><strong>ret (Tensor, optional)</strong> – 如果不是空， 结果将被保存在其中；否则，一个新tensor会被创建以保存结果。</li>
</ul>
<p><strong>返回值：</strong> 新tensor</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-add-column-alpha-v-beta-m">
<h4>singa.tensor.add_column(alpha, v, beta, M)<a class="headerlink" href="#singa-tensor-add-column-alpha-v-beta-m" title="Permalink to this headline">¶</a></h4>
<p>将v加到M的每个列向量, 定义M一列为m，m=alpha * v + beta * m</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>alpha (float)</strong> – v的系数</li>
<li><strong>v (Tensor)</strong> – 1维tensor</li>
<li><strong>beta (float)</strong> – M的系数</li>
<li><strong>M (Tensor)</strong> – 2维tensor</li>
</ul>
<p><strong>返回值：</strong> M</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-add-row-alpha-v-beta-m">
<h4>singa.tensor.add_row(alpha, v, beta, M)<a class="headerlink" href="#singa-tensor-add-row-alpha-v-beta-m" title="Permalink to this headline">¶</a></h4>
<p>将v加到M的每个行向量, 定义M一行为m，m=alpha * v + beta * m。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>alpha (float)</strong> – v的系数</li>
<li><strong>v (Tensor)</strong> – 1维tensor</li>
<li><strong>beta (float)</strong> – M的系数</li>
<li><strong>M (Tensor)</strong> – 2维tensor</li>
</ul>
<p><strong>返回值：</strong> M</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-average-t-axis-none">
<h4>singa.tensor.average(t, axis=None)<a class="headerlink" href="#singa-tensor-average-t-axis-none" title="Permalink to this headline">¶</a></h4>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 输入Tensor</li>
<li><strong>axis (int, optional)</strong> – 如果为空，取所有元素的平均值；否则，取给定维度的元素平均值。0表示列均值，1表示行均值。</li>
</ul>
<p><strong>返回值：</strong> 如果axis是空，返回一个float值；否则，返回一个新tensor</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-axpy-alpha-x-y">
<h4>singa.tensor.axpy(alpha, x, y)<a class="headerlink" href="#singa-tensor-axpy-alpha-x-y" title="Permalink to this headline">¶</a></h4>
<p>元素级别操作 y += alpha * x。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>alpha (float)</strong> – x的系数</li>
<li><strong>x (Tensor)</strong> – 被加的tensor</li>
<li><strong>y (Tensor)</strong> – 原tensor</li>
</ul>
<p><strong>返回值：</strong> y</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-bernoulli-p-t">
<h4>singa.tensor.bernoulli(p, t)<a class="headerlink" href="#singa-tensor-bernoulli-p-t" title="Permalink to this headline">¶</a></h4>
<p>对每个元素生成一个二进制位。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>p (float)</strong> – each element is 1 with probability p; and 0 with 1 - p</li>
<li><strong>t (Tensor)</strong> – the results are put into t</li>
</ul>
<p><strong>返回值：</strong> t</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-copy-data-to-from-dst-src-size-dst-offset-0-src-offset-0">
<h4>singa.tensor.copy_data_to_from(dst, src, size, dst_offset=0, src_offset=0)<a class="headerlink" href="#singa-tensor-copy-data-to-from-dst-src-size-dst-offset-0-src-offset-0" title="Permalink to this headline">¶</a></h4>
<p>将数据从一个tensor实例拷贝到另一个tensor实例。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>dst (Tensor)</strong> – 目标Tensor</li>
<li><strong>src (Tensor)</strong> – 源Tensor</li>
<li><strong>size (int)</strong> – 拷贝元素数目</li>
<li><strong>dst_offset (int)</strong> – 拷贝到dst元素在dst的起始偏移</li>
<li><strong>src_offset (int)</strong> – 待拷贝的元素在src中的起始偏移</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-div-lhs-rhs-ret-none">
<h4>singa.tensor.div(lhs, rhs, ret=None)<a class="headerlink" href="#singa-tensor-div-lhs-rhs-ret-none" title="Permalink to this headline">¶</a></h4>
<p>元素级别的除法。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>lhs (Tensor)</strong> – 左操作tensor</li>
<li><strong>rhs (Tensor)</strong> – 右操作tensor</li>
<li><strong>ret (Tensor, optional)</strong> – 如果非空，将把结果写入；否则，创建一个新tensor并将结果写入</li>
</ul>
<p><strong>返回值：</strong> 存有运算结果的tensor</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-eltwise-mult-lhs-rhs-ret-none">
<h4>singa.tensor.eltwise_mult(lhs, rhs, ret=None)<a class="headerlink" href="#singa-tensor-eltwise-mult-lhs-rhs-ret-none" title="Permalink to this headline">¶</a></h4>
<p>元素级别的乘法。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>lhs (Tensor)</strong> – 左操作tensor</li>
<li><strong>rhs (Tensor)</strong> – 右操作tensor</li>
<li><strong>ret (Tensor, optional)</strong> – 如果非空，将把结果写入；否则，创建一个新tensor并将结果写入</li>
</ul>
<p><strong>返回值：</strong> 保存运算结果的tensor</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-exp-t">
<h4>singa.tensor.exp(t)<a class="headerlink" href="#singa-tensor-exp-t" title="Permalink to this headline">¶</a></h4>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 输入tensor</li>
</ul>
<p><strong>返回值：</strong> 新tensor，其中元素为 y = exp(x)，x为t中元素</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-from-numpy-np-array">
<h4>singa.tensor.from_numpy(np_array)<a class="headerlink" href="#singa-tensor-from-numpy-np-array" title="Permalink to this headline">¶</a></h4>
<p>根据numpy数组的形状、数据类型和数值创建一个tensor。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>np_array</strong> – numpy数组</li>
</ul>
<p><strong>返回值：</strong> 分配在默认CppCPU设备上的tensor实例</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-gaussian-mean-std-t">
<h4>singa.tensor.gaussian(mean, std, t)<a class="headerlink" href="#singa-tensor-gaussian-mean-std-t" title="Permalink to this headline">¶</a></h4>
<p>按照给定高斯分布生成数值。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>mean (float)</strong> – 高斯分布的均值</li>
<li><strong>std (float)</strong> – 高斯分布的标准差</li>
<li><strong>t (Tensor)</strong> – 结果被存入t</li>
</ul>
<p><strong>返回值：</strong> t</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-ge-t-x">
<h4>singa.tensor.ge(t, x)<a class="headerlink" href="#singa-tensor-ge-t-x" title="Permalink to this headline">¶</a></h4>
<p>元素级别的比较，t &gt;= x。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 左操作数</li>
<li><strong>x (Tensor or float)</strong> – 右操作数</li>
</ul>
<p><strong>返回值：</strong> 0.0f 或 t[i] &gt;= x[i] ? 1.0f:0.0f</p>
<p><strong>返回值类型：</strong> tensor，每个元素为 t[i] &gt;= x ? 1.0f</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-gt-t-x">
<h4>singa.tensor.gt(t, x)<a class="headerlink" href="#singa-tensor-gt-t-x" title="Permalink to this headline">¶</a></h4>
<p>元素级别的比较，t &gt; x。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 左操作tensor</li>
<li><strong>x (Tensor or float)</strong> – 右操作tensor或数</li>
</ul>
<p><strong>返回值：</strong> 0.0f 或 t[i] &gt; x[i] ? 1.0f:0.0f</p>
<p><strong>返回值类型：</strong> tensor，每个元素为 t[i] &gt; x ? 1.0f</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-le-t-x">
<h4>singa.tensor.le(t, x)<a class="headerlink" href="#singa-tensor-le-t-x" title="Permalink to this headline">¶</a></h4>
<p>元素级别的比较，t &lt;= x。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 左操作tensor</li>
<li><strong>x (Tensor or float)</strong> – 右操作tensor或数</li>
</ul>
<p><strong>返回值：</strong> 0.0f 或 t[i] &lt;= x[i] ? 1.0f:0.0f</p>
<p><strong>返回值类型：</strong> tensor，每个元素为 t[i] &lt;= x ? 1.0f</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-lt-t-x">
<h4>singa.tensor.lt(t, x)<a class="headerlink" href="#singa-tensor-lt-t-x" title="Permalink to this headline">¶</a></h4>
<p>元素级别的比较，t &lt; x。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 左操作tensor</li>
<li><strong>x (Tensor or float)</strong> – 右操作tensor或数</li>
</ul>
<p><strong>返回值：</strong> 0.0f 或 t[i] &lt; x[i] ? 1.0f:0.0f</p>
<p><strong>返回值类型：</strong> tensor，每个元素为 t[i] &lt; x ? 1.0f</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-log-t">
<h4>singa.tensor.log(t)<a class="headerlink" href="#singa-tensor-log-t" title="Permalink to this headline">¶</a></h4>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 输入tensor</li>
</ul>
<p><strong>返回值：</strong> 一个新tensor，其元素值为y = log(x)，x是t中的元素</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-mult-a-b-c-none-alpha-1-0-beta-0-0">
<h4>singa.tensor.mult(A, B, C=None, alpha=1.0, beta=0.0)<a class="headerlink" href="#singa-tensor-mult-a-b-c-none-alpha-1-0-beta-0-0" title="Permalink to this headline">¶</a></h4>
<p>矩阵-矩阵或矩阵-向量乘法, 函数返回 C = alpha * A * B + beta * C。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>A (Tensor)</strong> – 2维Tensor</li>
<li><strong>B (Tensor)</strong> – 如果B是1维Tensor, 将调用GEMV做矩阵-向量乘法；否则将调用GEMM。</li>
<li><strong>C (Tensor, optional)</strong> – 存储结果；如果为空，将创建新tensor存储结果。</li>
<li><strong>alpha (float)</strong> – A * B 的系数</li>
<li><strong>beta (float)</strong> – C 的系数</li>
</ul>
<p><strong>返回值：</strong> 保存运算结果的tensor</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-pow-t-x-out-none">
<h4>singa.tensor.pow(t, x, out=None)<a class="headerlink" href="#singa-tensor-pow-t-x-out-none" title="Permalink to this headline">¶</a></h4>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 输入tensor</li>
<li><strong>x (float or Tensor)</strong> – 如果x是浮点数 y[i] = t[i]^x; 否则 y[i]= t[i]^x[i]</li>
<li><strong>out (None or Tensor)</strong> – 如果非空，将存入结果；否则，将创建一个新tensor保存结果。</li>
</ul>
<p><strong>返回值：</strong> 保存运算结果的tensor</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-relu-t">
<h4>singa.tensor.relu(t)<a class="headerlink" href="#singa-tensor-relu-t" title="Permalink to this headline">¶</a></h4>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 输入tensor</li>
</ul>
<p><strong>返回值：</strong> tensor，其中元素为 y = x 若x &gt;0；否则y = 0，x为t中元素</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-reshape-t-s">
<h4>singa.tensor.reshape(t, s)<a class="headerlink" href="#singa-tensor-reshape-t-s" title="Permalink to this headline">¶</a></h4>
<p>改变tensor的形状。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 待改变形状的tensor</li>
<li><strong>s (list<int>)</strong> – 新形状，体积和原tensor体积相同</li>
</ul>
<p><strong>返回值：</strong> 新tensor</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-sigmoid-t">
<h4>singa.tensor.sigmoid(t)<a class="headerlink" href="#singa-tensor-sigmoid-t" title="Permalink to this headline">¶</a></h4>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 输入tensor</li>
</ul>
<p><strong>返回值：</strong> tensor，其中元素为 y = sigmoid(x)，x为t中元素</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-sign-t">
<h4>singa.tensor.sign(t)<a class="headerlink" href="#singa-tensor-sign-t" title="Permalink to this headline">¶</a></h4>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 输入tensor</li>
</ul>
<p><strong>返回值：</strong> tensor，其中元素为 y = sign(x)，x为t中元素</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-sizeof-dtype">
<h4>singa.tensor.sizeof(dtype)<a class="headerlink" href="#singa-tensor-sizeof-dtype" title="Permalink to this headline">¶</a></h4>
<p><strong>返回值：</strong> 依据core.proto中定义的SINGA数据类型，返回给定类型所占Byte数目</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-softmax-t-out-none">
<h4>singa.tensor.softmax(t, out=None)<a class="headerlink" href="#singa-tensor-softmax-t-out-none" title="Permalink to this headline">¶</a></h4>
<p>对tensor每行做SoftMax。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 输入1维或2维tensor</li>
<li><strong>out (Tensor, 可选)</strong> – 如果非空，将存入结果</li>
</ul>
<p><strong>返回值：</strong> 保存操作结果的tensor</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-sqrt-t">
<h4>singa.tensor.sqrt(t)<a class="headerlink" href="#singa-tensor-sqrt-t" title="Permalink to this headline">¶</a></h4>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 输入tensor</li>
</ul>
<p><strong>返回值：</strong> tensor，其中元素为 y = sqrt(x)，x为t中元素</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-square-t">
<h4>singa.tensor.square(t)<a class="headerlink" href="#singa-tensor-square-t" title="Permalink to this headline">¶</a></h4>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 输入tensor</li>
</ul>
<p><strong>返回值：</strong> tensor，其中元素为 y = x * x，x为t中元素</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-sub-lhs-rhs-ret-none">
<h4>singa.tensor.sub(lhs, rhs, ret=None)<a class="headerlink" href="#singa-tensor-sub-lhs-rhs-ret-none" title="Permalink to this headline">¶</a></h4>
<p>元素级别的减法。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>lhs (Tensor)</strong> – 左操作tensor</li>
<li><strong>rhs (Tensor)</strong> – 右操作tensor</li>
<li><strong>ret (Tensor, 可选)</strong> – 如果非空，将存入结果；否则，将创建一个新tensor保存</li>
</ul>
<p><strong>返回值：</strong> 存放结果的tensor</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-sum-t-axis-none">
<h4>singa.tensor.sum(t, axis=None)<a class="headerlink" href="#singa-tensor-sum-t-axis-none" title="Permalink to this headline">¶</a></h4>
<p>在给定的维度上求和。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 输入Tensor</li>
<li><strong>axis (int, 可选)</strong> – 如果为空，将对所有元素求和；如果给定数值，将沿给定维度求和，比如：0 - 按列求和；1 - 按行求和。</li>
</ul>
<p><strong>返回值：</strong> 如果是对整体求和，返回一个浮点数；否则返回tensor</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-sum-columns-m">
<h4>singa.tensor.sum_columns(M)<a class="headerlink" href="#singa-tensor-sum-columns-m" title="Permalink to this headline">¶</a></h4>
<p>按列求和。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>M (Tensor)</strong> – 输入的2维tensor</li>
</ul>
<p><strong>返回值：</strong> 产生求和结果的tensor</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-sum-rows-m">
<h4>singa.tensor.sum_rows(M)<a class="headerlink" href="#singa-tensor-sum-rows-m" title="Permalink to this headline">¶</a></h4>
<p>按行求和。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>M (Tensor)</strong> – 输入的2维tensor</li>
</ul>
<p><strong>返回值：</strong> 产生求和结果的tensor</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-tanh-t">
<h4>singa.tensor.tanh(t)<a class="headerlink" href="#singa-tensor-tanh-t" title="Permalink to this headline">¶</a></h4>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 输入tensor</li>
</ul>
<p>**返回值：**tensor，其中元素为 y = tanh(x)，x为t中元素</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-to-host-t">
<h4>singa.tensor.to_host(t)<a class="headerlink" href="#singa-tensor-to-host-t" title="Permalink to this headline">¶</a></h4>
<p>将数据拷贝到host设备上。</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-to-numpy-t">
<h4>singa.tensor.to_numpy(t)<a class="headerlink" href="#singa-tensor-to-numpy-t" title="Permalink to this headline">¶</a></h4>
<p>拷贝tensor数据到numpy数组。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>t (Tensor)</strong> – 输入tensor</li>
</ul>
<p><strong>返回值：</strong> numpy数组</p>
</div>
<hr class="docutils" />
<div class="section" id="singa-tensor-uniform-low-high-t">
<h4>singa.tensor.uniform(low, high, t)<a class="headerlink" href="#singa-tensor-uniform-low-high-t" title="Permalink to this headline">¶</a></h4>
<p>按照均匀分布生成数值。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><strong>low (float)</strong> – 下界</li>
<li><strong>hight (float)</strong> – 上届</li>
<li><strong>t (Tensor)</strong> – 结果存入t</li>
</ul>
<p><strong>返回值：</strong> t</p>
<hr class="docutils" />
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="layer.html" class="btn btn-neutral float-right" title="层(Layer)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="device.html" class="btn btn-neutral float-left" title="设备(Device)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019 The Apache Software Foundation. All rights reserved. Apache SINGA, Apache, the Apache feather logo, and the Apache SINGA project logos are trademarks of The Apache Software Foundation. All other marks mentioned may be trademarks or registered trademarks of their respective owners.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  

<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> singa </span>
    v: latest
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Languages</dt>
      <dd><a href="../../index.html">English</a></dd>
      <dd><a href=".././index.html">中文</a></dd>
    </dl>
    <dl>
      <dt>Versions</dt>
      <dd><a href="http://singa.apache.org/v0.3.0/">0.3</a></dd>
      <dd><a href="http://singa.apache.org/v1.1.0/">1.1</a></dd>
    </dl>

  </div>
  <a href="http://www.apache.org"
    style="color:lightblue;padding: 5px; font-size: 10px; text-align: center; text-decoration: none; margin: 5px 2px;">Foundation</a>
  <a href="http://www.apache.org/events/current-event"
    style="color:lightblue;padding: 5px; font-size: 10px; text-align: center; text-decoration: none; margin: 5px 2px;">Events</a>
  <a href="http://www.apache.org/foundation/thanks.html"
    style="color:lightblue;padding: 5px; font-size: 10px; text-align: center; text-decoration: none; margin: 5px 2px;">Thanks</a>
  <a href="http://www.apache.org/foundation/sponsorship.html"
    style="color:lightblue;padding: 5px; font-size: 10px;  text-align: center; text-decoration: none; margin: 5px 2px;">Sponsorship</a>
  <a href="http://www.apache.org/licenses/"
    style="color:lightblue;padding: 5px; font-size: 10px;  text-align: center; text-decoration: none; margin: 5px 2px;">License</a>
  <br>
  <a href="https://github.com/apache/singa" class="fa fa-github"
    style="padding: 10px; font-size: 20px; width: 30px; text-align: center; text-decoration: none; margin: 5px 2px;"></a>
  <a href="https://aws.amazon.com/marketplace/seller-profile?id=5bcac385-12c4-4802-aec7-351e09b77b4c" class="fab fa-aws"
    style="padding: 10px; font-size: 20px; width: 30px; text-align: center; text-decoration: none; margin: 5px 2px;"></a>
  <a href="https://hub.docker.com/r/apache/singa/" class="fab fa-docker"
    style="padding: 10px; font-size: 20px; width: 30px; text-align: center; text-decoration: none; margin: 5px 2px;"></a>
  <a href="https://www.linkedin.com/groups/13550034" class="fa fa-linkedin"
    style="padding: 10px; font-size: 20px; width: 30px; text-align: center; text-decoration: none; margin: 5px 2px;"></a>
  <a href="https://twitter.com/ApacheSinga" class="fa fa-twitter"
    style="padding: 10px; font-size: 20px; width: 30px; text-align: center; text-decoration: none; margin: 5px 2px;"></a>
  <a href="https://www.facebook.com/Apache-SINGA-347284219056544/" class="fa fa-facebook"
    style="padding: 10px; font-size: 20px; width: 30px; text-align: center; text-decoration: none; margin: 5px 2px;"></a>
  <a href="https://www.researchgate.net/project/Apache-SINGA" class="fab fa-researchgate"
    style="padding: 10px; font-size: 20px; width: 30px; text-align: center; text-decoration: none; margin: 5px 2px;"></a>

</div>

<a href="https://github.com/apache/singa">
  <img style="position: absolute; top: 0; right: 0; border: 0; z-index: 10000;"
    src="https://s3.amazonaws.com/github/ribbons/forkme_right_orange_ff7600.png" alt="Fork me on GitHub">
</a>

 


</body>
</html>