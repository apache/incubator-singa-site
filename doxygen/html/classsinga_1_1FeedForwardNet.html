<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Apache Singa: singa::FeedForwardNet Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Apache Singa
   </div>
   <div id="projectbrief">A General Distributed Deep Learning Library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesinga.html">singa</a></li><li class="navelem"><a class="el" href="classsinga_1_1FeedForwardNet.html">FeedForwardNet</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="classsinga_1_1FeedForwardNet-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">singa::FeedForwardNet Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>The feed-forward neural net.  
 <a href="classsinga_1_1FeedForwardNet.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="feed__forward__net_8h_source.html">feed_forward_net.h</a>&gt;</code></p>
<div class="dynheader">
Collaboration diagram for singa::FeedForwardNet:</div>
<div class="dyncontent">
<div class="center"><img src="classsinga_1_1FeedForwardNet__coll__graph.png" border="0" usemap="#singa_1_1FeedForwardNet_coll__map" alt="Collaboration graph"/></div>
<!-- MAP 0 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a29e8b40d21d2aa9983c5b87231095edc"><td class="memItemLeft" align="right" valign="top"><a id="a29e8b40d21d2aa9983c5b87231095edc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a29e8b40d21d2aa9983c5b87231095edc">~FeedForwardNet</a> ()</td></tr>
<tr class="memdesc:a29e8b40d21d2aa9983c5b87231095edc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Delete all layers. <br /></td></tr>
<tr class="separator:a29e8b40d21d2aa9983c5b87231095edc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3802c112004a7587c6f61ef07c6fb776"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classsinga_1_1Layer.html">Layer</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a3802c112004a7587c6f61ef07c6fb776">Add</a> (std::shared_ptr&lt; <a class="el" href="classsinga_1_1Layer.html">Layer</a> &gt; layer)</td></tr>
<tr class="memdesc:a3802c112004a7587c6f61ef07c6fb776"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a layer with the assumption that.  <a href="#a3802c112004a7587c6f61ef07c6fb776">More...</a><br /></td></tr>
<tr class="separator:a3802c112004a7587c6f61ef07c6fb776"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a063475b1cbd8a7345c9dd5fb31fe60be"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classsinga_1_1Layer.html">Layer</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a063475b1cbd8a7345c9dd5fb31fe60be">Add</a> (const LayerConf &amp;conf, const Shape *sample_shape=nullptr)</td></tr>
<tr class="memdesc:a063475b1cbd8a7345c9dd5fb31fe60be"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a layer by providing its configuration, and setup it.  <a href="#a063475b1cbd8a7345c9dd5fb31fe60be">More...</a><br /></td></tr>
<tr class="separator:a063475b1cbd8a7345c9dd5fb31fe60be"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae1a14998b17a633b3106eeddf33b4eb2"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#ae1a14998b17a633b3106eeddf33b4eb2">Compile</a> (bool shuffle, <a class="el" href="classsinga_1_1Optimizer.html">Optimizer</a> *opt, <a class="el" href="classsinga_1_1Loss.html">Loss</a> *loss, <a class="el" href="classsinga_1_1Metric.html">Metric</a> *metric)</td></tr>
<tr class="memdesc:ae1a14998b17a633b3106eeddf33b4eb2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set some fields used for training and evaluating the neural net.  <a href="#ae1a14998b17a633b3106eeddf33b4eb2">More...</a><br /></td></tr>
<tr class="separator:ae1a14998b17a633b3106eeddf33b4eb2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac9d8bfa11309bea1f451994809e2c535"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#ac9d8bfa11309bea1f451994809e2c535">Compile</a> (bool shuffle, bool to_register, std::shared_ptr&lt; <a class="el" href="classsinga_1_1Updater.html">Updater</a> &gt; updater, <a class="el" href="classsinga_1_1Loss.html">Loss</a> *loss, <a class="el" href="classsinga_1_1Metric.html">Metric</a> *metric)</td></tr>
<tr class="memdesc:ac9d8bfa11309bea1f451994809e2c535"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set some fields used for training and evaluating the neural net.  <a href="#ac9d8bfa11309bea1f451994809e2c535">More...</a><br /></td></tr>
<tr class="separator:ac9d8bfa11309bea1f451994809e2c535"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32ef60dad6226d6c03e5917083be5830"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a32ef60dad6226d6c03e5917083be5830">Train</a> (size_t batchsize, int nb_epoch, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;y, float val_split=0.0f)</td></tr>
<tr class="memdesc:a32ef60dad6226d6c03e5917083be5830"><td class="mdescLeft">&#160;</td><td class="mdescRight">Conduct the training giving the training data 'x' and label 'y'.  <a href="#a32ef60dad6226d6c03e5917083be5830">More...</a><br /></td></tr>
<tr class="separator:a32ef60dad6226d6c03e5917083be5830"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a63ddd842dbf10260100e6a32735dcbb9"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a63ddd842dbf10260100e6a32735dcbb9">Train</a> (size_t batchsize, int nb_epoch, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;y, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;val_x, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;val_y)</td></tr>
<tr class="memdesc:a63ddd842dbf10260100e6a32735dcbb9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Conduct the training given the training and validation data.  <a href="#a63ddd842dbf10260100e6a32735dcbb9">More...</a><br /></td></tr>
<tr class="separator:a63ddd842dbf10260100e6a32735dcbb9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6906ac848b6d934fe0ce515dddc386ad"><td class="memItemLeft" align="right" valign="top"><a id="a6906ac848b6d934fe0ce515dddc386ad"></a>
const std::pair&lt; float, float &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a6906ac848b6d934fe0ce515dddc386ad">TrainOnBatch</a> (int epoch, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;y)</td></tr>
<tr class="memdesc:a6906ac848b6d934fe0ce515dddc386ad"><td class="mdescLeft">&#160;</td><td class="mdescRight">Train the neural net over one batch of training data. <br /></td></tr>
<tr class="separator:a6906ac848b6d934fe0ce515dddc386ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa7c1e721ff9ca9f1a8e11ae9855e69af"><td class="memItemLeft" align="right" valign="top">std::pair&lt; <a class="el" href="classsinga_1_1Tensor.html">Tensor</a>, <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#aa7c1e721ff9ca9f1a8e11ae9855e69af">Evaluate</a> (const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;y, size_t batchsize=128)</td></tr>
<tr class="memdesc:aa7c1e721ff9ca9f1a8e11ae9855e69af"><td class="mdescLeft">&#160;</td><td class="mdescRight">Evaluate the neural net with given data.  <a href="#aa7c1e721ff9ca9f1a8e11ae9855e69af">More...</a><br /></td></tr>
<tr class="separator:aa7c1e721ff9ca9f1a8e11ae9855e69af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c74012b7c57f51a5fb2218d82a0fdff"><td class="memItemLeft" align="right" valign="top"><a id="a7c74012b7c57f51a5fb2218d82a0fdff"></a>
std::pair&lt; <a class="el" href="classsinga_1_1Tensor.html">Tensor</a>, <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a7c74012b7c57f51a5fb2218d82a0fdff">EvaluateOnBatch</a> (const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;y)</td></tr>
<tr class="memdesc:a7c74012b7c57f51a5fb2218d82a0fdff"><td class="mdescLeft">&#160;</td><td class="mdescRight">Evaluate the neural net for one batch of data. <br /></td></tr>
<tr class="separator:a7c74012b7c57f51a5fb2218d82a0fdff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0cd9bb19e17ac2c54f44503459679ccb"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a0cd9bb19e17ac2c54f44503459679ccb">Predict</a> (const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;x, size_t batchsize=128)</td></tr>
<tr class="memdesc:a0cd9bb19e17ac2c54f44503459679ccb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Predict the probability distributation over candicate classes for each data sample.  <a href="#a0cd9bb19e17ac2c54f44503459679ccb">More...</a><br /></td></tr>
<tr class="separator:a0cd9bb19e17ac2c54f44503459679ccb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a63bf8f4ce71653773137d48a71615209"><td class="memItemLeft" align="right" valign="top"><a id="a63bf8f4ce71653773137d48a71615209"></a>
const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a63bf8f4ce71653773137d48a71615209">PredictOnBatch</a> (const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;x)</td></tr>
<tr class="memdesc:a63bf8f4ce71653773137d48a71615209"><td class="mdescLeft">&#160;</td><td class="mdescRight">Predict for one batch data. <br /></td></tr>
<tr class="separator:a63bf8f4ce71653773137d48a71615209"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c84ffddc1f721fd8068e316e164683a"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a9c84ffddc1f721fd8068e316e164683a">Forward</a> (int flag, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;x)</td></tr>
<tr class="memdesc:a9c84ffddc1f721fd8068e316e164683a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Forward layers one by one using the data batch 'x'.  <a href="#a9c84ffddc1f721fd8068e316e164683a">More...</a><br /></td></tr>
<tr class="separator:a9c84ffddc1f721fd8068e316e164683a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a49e566021fc2e388b7b4bdb0bb84ce53"><td class="memItemLeft" align="right" valign="top">const vector&lt; <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a49e566021fc2e388b7b4bdb0bb84ce53">Backward</a> (int flag, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;grad)</td></tr>
<tr class="memdesc:a49e566021fc2e388b7b4bdb0bb84ce53"><td class="mdescLeft">&#160;</td><td class="mdescRight">Backward layers one by one using the gradient batch 'grad'.  <a href="#a49e566021fc2e388b7b4bdb0bb84ce53">More...</a><br /></td></tr>
<tr class="separator:a49e566021fc2e388b7b4bdb0bb84ce53"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a790aeb0ab8f3e0b91f4fc6bdecf55f4e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classsinga_1_1FeedForwardNet.html">FeedForwardNet</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a790aeb0ab8f3e0b91f4fc6bdecf55f4e">Clone</a> (std::shared_ptr&lt; <a class="el" href="classsinga_1_1Device.html">Device</a> &gt; device)</td></tr>
<tr class="memdesc:a790aeb0ab8f3e0b91f4fc6bdecf55f4e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Clone the neuaral net by cloning every layer to the given device.  <a href="#a790aeb0ab8f3e0b91f4fc6bdecf55f4e">More...</a><br /></td></tr>
<tr class="separator:a790aeb0ab8f3e0b91f4fc6bdecf55f4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a165e4e2bad62e2ad6fb9dcaed1e2b568"><td class="memItemLeft" align="right" valign="top"><a id="a165e4e2bad62e2ad6fb9dcaed1e2b568"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a165e4e2bad62e2ad6fb9dcaed1e2b568">ToDevice</a> (std::shared_ptr&lt; <a class="el" href="classsinga_1_1Device.html">Device</a> &gt; device)</td></tr>
<tr class="memdesc:a165e4e2bad62e2ad6fb9dcaed1e2b568"><td class="mdescLeft">&#160;</td><td class="mdescRight">Move the layer data to the given device. <br /></td></tr>
<tr class="separator:a165e4e2bad62e2ad6fb9dcaed1e2b568"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8ea903e506240ca71da489975a3b8fc0"><td class="memItemLeft" align="right" valign="top"><a id="a8ea903e506240ca71da489975a3b8fc0"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ToHost</b> ()</td></tr>
<tr class="separator:a8ea903e506240ca71da489975a3b8fc0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a554d848ec434290b2de971c91c0f2e83"><td class="memItemLeft" align="right" valign="top"><a id="a554d848ec434290b2de971c91c0f2e83"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a554d848ec434290b2de971c91c0f2e83">AsType</a> (DataType dtype)</td></tr>
<tr class="memdesc:a554d848ec434290b2de971c91c0f2e83"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the data type of each layer. <br /></td></tr>
<tr class="separator:a554d848ec434290b2de971c91c0f2e83"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a15306a1719ecd371e7da99d387dbf80c"><td class="memItemLeft" align="right" valign="top"><a id="a15306a1719ecd371e7da99d387dbf80c"></a>
std::thread&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a15306a1719ecd371e7da99d387dbf80c">TrainThread</a> (size_t batchsize, int nb_epoch, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;y, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;val_x, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;val_y)</td></tr>
<tr class="memdesc:a15306a1719ecd371e7da99d387dbf80c"><td class="mdescLeft">&#160;</td><td class="mdescRight">A wrapper method to spawn a thread to execute <a class="el" href="classsinga_1_1FeedForwardNet.html#a32ef60dad6226d6c03e5917083be5830" title="Conduct the training giving the training data &#39;x&#39; and label &#39;y&#39;. ">Train()</a> method. <br /></td></tr>
<tr class="separator:a15306a1719ecd371e7da99d387dbf80c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62e80931af5311dda492f838f4274dcd"><td class="memItemLeft" align="right" valign="top"><a id="a62e80931af5311dda492f838f4274dcd"></a>
std::thread&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsinga_1_1FeedForwardNet.html#a62e80931af5311dda492f838f4274dcd">TrainThread</a> (size_t batchsize, int nb_epoch, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;x, const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;y)</td></tr>
<tr class="memdesc:a62e80931af5311dda492f838f4274dcd"><td class="mdescLeft">&#160;</td><td class="mdescRight">A wrapper method to spawn a thread to execute <a class="el" href="classsinga_1_1FeedForwardNet.html#a32ef60dad6226d6c03e5917083be5830" title="Conduct the training giving the training data &#39;x&#39; and label &#39;y&#39;. ">Train()</a> method. <br /></td></tr>
<tr class="separator:a62e80931af5311dda492f838f4274dcd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afeaf8b35e04ad3980d6a342d92e5cbf2"><td class="memItemLeft" align="right" valign="top"><a id="afeaf8b35e04ad3980d6a342d92e5cbf2"></a>
const vector&lt; std::shared_ptr&lt; <a class="el" href="classsinga_1_1Layer.html">Layer</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>layers</b> () const</td></tr>
<tr class="separator:afeaf8b35e04ad3980d6a342d92e5cbf2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a341bd33c881f12dccd743c5451bd2e4e"><td class="memItemLeft" align="right" valign="top"><a id="a341bd33c881f12dccd743c5451bd2e4e"></a>
const vector&lt; string &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>GetParamNames</b> () const</td></tr>
<tr class="separator:a341bd33c881f12dccd743c5451bd2e4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0287898232819a62f9bc9f8ad3676e68"><td class="memItemLeft" align="right" valign="top"><a id="a0287898232819a62f9bc9f8ad3676e68"></a>
const vector&lt; ParamSpec &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>GetParamSpecs</b> () const</td></tr>
<tr class="separator:a0287898232819a62f9bc9f8ad3676e68"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e09bdcde78c5ce20b3e6239e89781cc"><td class="memItemLeft" align="right" valign="top"><a id="a8e09bdcde78c5ce20b3e6239e89781cc"></a>
const vector&lt; <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>GetParamValues</b> () const</td></tr>
<tr class="separator:a8e09bdcde78c5ce20b3e6239e89781cc"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:ab904787b4b0371982775fd5c02772896"><td class="memItemLeft" align="right" valign="top"><a id="ab904787b4b0371982775fd5c02772896"></a>
vector&lt; std::shared_ptr&lt; <a class="el" href="classsinga_1_1Layer.html">Layer</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>layers_</b></td></tr>
<tr class="separator:ab904787b4b0371982775fd5c02772896"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a251d81ed71e141a06424601f6a6522b3"><td class="memItemLeft" align="right" valign="top"><a id="a251d81ed71e141a06424601f6a6522b3"></a>
std::shared_ptr&lt; <a class="el" href="classsinga_1_1Updater.html">Updater</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>updater_</b></td></tr>
<tr class="separator:a251d81ed71e141a06424601f6a6522b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a10bc978970408d3d7d1e4903992a30e0"><td class="memItemLeft" align="right" valign="top"><a id="a10bc978970408d3d7d1e4903992a30e0"></a>
<a class="el" href="classsinga_1_1Loss.html">Loss</a> *&#160;</td><td class="memItemRight" valign="bottom"><b>loss_</b></td></tr>
<tr class="separator:a10bc978970408d3d7d1e4903992a30e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad90188b42d8563d080ddf312f6199edb"><td class="memItemLeft" align="right" valign="top"><a id="ad90188b42d8563d080ddf312f6199edb"></a>
<a class="el" href="classsinga_1_1Metric.html">Metric</a> *&#160;</td><td class="memItemRight" valign="bottom"><b>metric_</b></td></tr>
<tr class="separator:ad90188b42d8563d080ddf312f6199edb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0993b0a0edffaec0c72d02247cebb258"><td class="memItemLeft" align="right" valign="top"><a id="a0993b0a0edffaec0c72d02247cebb258"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>shuffle_</b> = true</td></tr>
<tr class="separator:a0993b0a0edffaec0c72d02247cebb258"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb7d4087ddb09e3fcdbb5c097ddcbfbe"><td class="memItemLeft" align="right" valign="top"><a id="adb7d4087ddb09e3fcdbb5c097ddcbfbe"></a>
<a class="el" href="classsinga_1_1Device.html">Device</a> *&#160;</td><td class="memItemRight" valign="bottom"><b>device_</b> = nullptr</td></tr>
<tr class="separator:adb7d4087ddb09e3fcdbb5c097ddcbfbe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3f1127eecaed2e0e44bd6a0e5c134113"><td class="memItemLeft" align="right" valign="top"><a id="a3f1127eecaed2e0e44bd6a0e5c134113"></a>
DataType&#160;</td><td class="memItemRight" valign="bottom"><b>dtype_</b> = kFloat32</td></tr>
<tr class="separator:a3f1127eecaed2e0e44bd6a0e5c134113"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>The feed-forward neural net. </p>
<p>It provides functions for constructing the layers, access layer parameters, and conducting training, evaluation and prediction. </p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a3802c112004a7587c6f61ef07c6fb776"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3802c112004a7587c6f61ef07c6fb776">&#9670;&nbsp;</a></span>Add() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt;<a class="el" href="classsinga_1_1Layer.html">Layer</a>&gt; singa::FeedForwardNet::Add </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classsinga_1_1Layer.html">Layer</a> &gt;&#160;</td>
          <td class="paramname"><em>layer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Add a layer with the assumption that. </p>
<ol type="1">
<li>this function is called in correct order, i.e., the layers are added following the topological order.</li>
<li>this layer has already been setup (Setup function is called outside). The layer will be freed in the destructor of <a class="el" href="classsinga_1_1FeedForwardNet.html" title="The feed-forward neural net. ">FeedForwardNet</a>. </li>
</ol>

</div>
</div>
<a id="a063475b1cbd8a7345c9dd5fb31fe60be"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a063475b1cbd8a7345c9dd5fb31fe60be">&#9670;&nbsp;</a></span>Add() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt;<a class="el" href="classsinga_1_1Layer.html">Layer</a>&gt; singa::FeedForwardNet::Add </td>
          <td>(</td>
          <td class="paramtype">const LayerConf &amp;&#160;</td>
          <td class="paramname"><em>conf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Shape *&#160;</td>
          <td class="paramname"><em>sample_shape</em> = <code>nullptr</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Add a layer by providing its configuration, and setup it. </p>
<p>Assume the layer is added in corret order. For the first layer, 'sample_shape' (the input sample shape) is necessary for calling Setup(). </p>

</div>
</div>
<a id="a49e566021fc2e388b7b4bdb0bb84ce53"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a49e566021fc2e388b7b4bdb0bb84ce53">&#9670;&nbsp;</a></span>Backward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const vector&lt;<a class="el" href="classsinga_1_1Tensor.html">Tensor</a>&gt; singa::FeedForwardNet::Backward </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>flag</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Backward layers one by one using the gradient batch 'grad'. </p>
<p>Returns the parameter gradients. </p>

</div>
</div>
<a id="a790aeb0ab8f3e0b91f4fc6bdecf55f4e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a790aeb0ab8f3e0b91f4fc6bdecf55f4e">&#9670;&nbsp;</a></span>Clone()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classsinga_1_1FeedForwardNet.html">FeedForwardNet</a> singa::FeedForwardNet::Clone </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classsinga_1_1Device.html">Device</a> &gt;&#160;</td>
          <td class="paramname"><em>device</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Clone the neuaral net by cloning every layer to the given device. </p>
<p>If 'device' is nullptr, then clone it one the current device. </p>

</div>
</div>
<a id="ae1a14998b17a633b3106eeddf33b4eb2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae1a14998b17a633b3106eeddf33b4eb2">&#9670;&nbsp;</a></span>Compile() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void singa::FeedForwardNet::Compile </td>
          <td>(</td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>shuffle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classsinga_1_1Optimizer.html">Optimizer</a> *&#160;</td>
          <td class="paramname"><em>opt</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classsinga_1_1Loss.html">Loss</a> *&#160;</td>
          <td class="paramname"><em>loss</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classsinga_1_1Metric.html">Metric</a> *&#160;</td>
          <td class="paramname"><em>metric</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Set some fields used for training and evaluating the neural net. </p>
<p>This method will instantiate an <a class="el" href="classsinga_1_1Updater.html" title="Basic Updater class just forward all the method function call to the wrapped Optimizer. ">Updater</a> ,then wrap the Optimier into <a class="el" href="classsinga_1_1Updater.html" title="Basic Updater class just forward all the method function call to the wrapped Optimizer. ">Updater</a> and always register the parameters of the net instance. If the neural net is constructed for evaluation only, then 'opt' is not necessary; But for training, both 'opt' and 'loss' are necessary. 'shuffle' indicates shuffling training samples within one epoch it is valid using <a class="el" href="classsinga_1_1FeedForwardNet.html#a32ef60dad6226d6c03e5917083be5830" title="Conduct the training giving the training data &#39;x&#39; and label &#39;y&#39;. ">Train()</a>. If to_register is set true, parameter will be registered in <a class="el" href="classsinga_1_1Updater.html" title="Basic Updater class just forward all the method function call to the wrapped Optimizer. ">Updater</a>.; </p>

</div>
</div>
<a id="ac9d8bfa11309bea1f451994809e2c535"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac9d8bfa11309bea1f451994809e2c535">&#9670;&nbsp;</a></span>Compile() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void singa::FeedForwardNet::Compile </td>
          <td>(</td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>shuffle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>to_register</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classsinga_1_1Updater.html">Updater</a> &gt;&#160;</td>
          <td class="paramname"><em>updater</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classsinga_1_1Loss.html">Loss</a> *&#160;</td>
          <td class="paramname"><em>loss</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classsinga_1_1Metric.html">Metric</a> *&#160;</td>
          <td class="paramname"><em>metric</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Set some fields used for training and evaluating the neural net. </p>
<p>This method is mainly used in parallel training, where we need multiple neuralnet instances. If the neural net is constructed for evaluation only, then 'updater' is not necessary; But for training, both 'opt' and 'loss' are necessary. 'shuffle' indicates shuffling training samples within one epoch it is valid using <a class="el" href="classsinga_1_1FeedForwardNet.html#a32ef60dad6226d6c03e5917083be5830" title="Conduct the training giving the training data &#39;x&#39; and label &#39;y&#39;. ">Train()</a>. If to_register is set true, parameter will be registered in <a class="el" href="classsinga_1_1Updater.html" title="Basic Updater class just forward all the method function call to the wrapped Optimizer. ">Updater</a>.; </p>

</div>
</div>
<a id="aa7c1e721ff9ca9f1a8e11ae9855e69af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa7c1e721ff9ca9f1a8e11ae9855e69af">&#9670;&nbsp;</a></span>Evaluate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::pair&lt;<a class="el" href="classsinga_1_1Tensor.html">Tensor</a>, <a class="el" href="classsinga_1_1Tensor.html">Tensor</a>&gt; singa::FeedForwardNet::Evaluate </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>batchsize</em> = <code>128</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Evaluate the neural net with given data. </p>
<p>Returns one tensor for loss values and one tensor for metric values; Each sample would have a loss value and a metric value (if 'metic' is set in <a class="el" href="classsinga_1_1FeedForwardNet.html#ae1a14998b17a633b3106eeddf33b4eb2" title="Set some fields used for training and evaluating the neural net. ">Compile()</a>).'batchsize' is used for controlling the memory footprint. It should be smaller than the total number of samples. Due to memory limit, 'x' and 'y' could not be very large. Hence, it is typically used for small training datasets, e.g., cifar10 and MNIST which can be stored in main memory. </p>

</div>
</div>
<a id="a9c84ffddc1f721fd8068e316e164683a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c84ffddc1f721fd8068e316e164683a">&#9670;&nbsp;</a></span>Forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> singa::FeedForwardNet::Forward </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>flag</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Forward layers one by one using the data batch 'x'. </p>
<p>Returns the prediction results (from the last layer). </p>

</div>
</div>
<a id="a0cd9bb19e17ac2c54f44503459679ccb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0cd9bb19e17ac2c54f44503459679ccb">&#9670;&nbsp;</a></span>Predict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> singa::FeedForwardNet::Predict </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>batchsize</em> = <code>128</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Predict the probability distributation over candicate classes for each data sample. </p>
<p>'batchsize' is used for controlling the memory footprint. It should be smaller than the total number of samples. Due to memory limit, 'x' and 'y' could not be very large. Hence, it is typically used for small training datasets, e.g., cifar10 and MNIST which can be stored in main memory. </p>

</div>
</div>
<a id="a32ef60dad6226d6c03e5917083be5830"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a32ef60dad6226d6c03e5917083be5830">&#9670;&nbsp;</a></span>Train() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void singa::FeedForwardNet::Train </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>batchsize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nb_epoch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>val_split</em> = <code>0.0f</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Conduct the training giving the training data 'x' and label 'y'. </p>
<p>'val_split' of training data is used for validation. Validation is performance before every epoch. Due to memory limit, 'x' and 'y' could not be very large. Hence, it is typically used for small training datasets, e.g., cifar10 and MNIST which can be stored in main memory. </p>

</div>
</div>
<a id="a63ddd842dbf10260100e6a32735dcbb9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a63ddd842dbf10260100e6a32735dcbb9">&#9670;&nbsp;</a></span>Train() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void singa::FeedForwardNet::Train </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>batchsize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nb_epoch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>val_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classsinga_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>val_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Conduct the training given the training and validation data. </p>
<p>Validation is performance before every epoch. Due to memory limit, 'x' and 'y' could not be very large. Hence, it is typically used for small training datasets, e.g., cifar10 and MNIST which can be stored in main memory. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/home/moaz/incubator-singa/include/singa/model/<a class="el" href="feed__forward__net_8h_source.html">feed_forward_net.h</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Mon Apr 22 2019 12:27:05 for Apache Singa by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
